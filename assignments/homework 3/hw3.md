My text of choice in the original version
I chose this text as it describes one of my favourite stand up/comedy specials. The article is full of idiomatic expressions, expressive and decriptive language which is why it's ideal for showing how tokenization differs in languages (especially with all the names, quotations and puntcutation in the article).

english_text = """Well, now we know what Bo Burnham did with his lockdown. Inside is his new Netflix special, created alone in his LA home throughout 2020. And it was not – if its narrative, and the evidence of our own eyes, is to be believed – a project casually tossed off to pass the time. It is, rather, a comedy Gesamtkunstwerk, a journey to the nerve-centre of the quarantined entertainer’s mind, a son et lumière Robinson Crusoe musical for the age of not just social but digital isolation. It could be a breakdown – or it could be the pandemic’s wildest gift to comedy. But is it comedy? Naysayers may complain that, with silences in laughter’s place, bleak jokes, and sections that eschew humour entirely, Inside has little comical about it. But if the material isn’t chucklesome, you’ll laugh with sheer astonishment at the accomplishment of Burnham’s enterprise. This prodigiously talented act has performed an extraordinary feat of construction and production, its restless audio-visual invention drastically expanding lockdown’s dramatic, comic and emotional range. Inside traces, non-chronologically, a year in Burnham’s life, spent in a small, loft-like room, creating this comedy special to keep despair at bay. It starts optimistic, with a song sending up his white-saviour complex, promising to “heal the world with comedy”. The messianic imagery recurs as Burnham, straggly of beard, flounces around in his pants. There are Lewis Carroll overtones, too: our host is too big for the door in and out of this looking-glass word, where he turns 30 for our pleasure, debates geopolitics with a sock puppet, and, at one point, commentates recursively on footage of the previous scene. Among these shards from a fracturing psyche, there’s social commentary: droll electro-pop about white women’s Instagram pages, Jeff Bezos and the alienation of internet culture. Burnham reflects on his own trajectory, too, from housebound teen YouTube star to, er, housebound burned-out comedy megastar. “So this is how it ends,” he sings, “I promise never to go out again.” Can he, ever? What would it mean to do so, after all this? This claustrophobic masterpiece will leave you wondering – and reeling."""

polish_text = """Cóż, teraz wiemy, co Bo Burnham robił podczas lockdownu. W środku znajduje się jego nowy program specjalny dla serwisu Netflix, stworzony samodzielnie w jego domu w Los Angeles w ciągu 2020 roku. I nie był to – jeśli wierzyć narracji i temu, co widzieliśmy na własne oczy – projekt zrobiony od niechcenia, aby zabić czas. Jest to raczej komediowe Gesamtkunstwerk, podróż do centrum nerwowego umysłu artysty poddawanego kwarantannie, musical Robinson Crusoe z efektami świetlnymi i dźwiękowymi, przeznaczony nie tylko dla epoki izolacji społecznej, ale także cyfrowej. Może to być załamanie nerwowe – lub najdzikszy prezent pandemii dla komedii. Ale czy to komedia? Krytycy mogą narzekać, że Inside nie ma w sobie nic komicznego, ponieważ zamiast śmiechu pojawiają się cisze, ponure żarty i fragmenty całkowicie pozbawione humoru. Ale nawet jeśli materiał nie jest komiczny, to i tak będziesz się śmiać z czystego zdumienia osiągnięciem Burnhama. Ten niezwykle utalentowany artysta dokonał niezwykłego wyczynu w zakresie konstrukcji i produkcji, a jego nieustanne wynalazki audiowizualne znacznie poszerzyły dramatyczny, komiczny i emocjonalny zakres lockdownu.Inside w sposób niechronologiczny śledzi, rok z życia Burnhama, spędzony w małym pokoju przypominającym loft, gdzie tworzył ten specjalny program komediowy, aby powstrzymać rozpacz. Zaczyna się optymistycznie, piosenką wyśmiewającą jego kompleks białego wybawiciela, obiecującą „uzdrowić świat komedią”. Mesjanistyczna symbolika powraca, gdy Burnham, z niechlujną brodą, paraduje w samych spodniach. Widać tu również nawiązania do Lewisa Carrolla: nasz gospodarz jest zbyt duży, by przejść przez drzwi do i z tego lustrzanego świata, gdzie dla naszej przyjemności kończy 30 lat, debatuje o geopolityce z kukiełką skarpetkową, a w pewnym momencie komentuje rekurencyjnie materiał filmowy z poprzedniej sceny. Wśród tych fragmentów rozbitej psychiki pojawiają się komentarze społeczne: zabawny electro-pop o stronach białych kobiet na Instagramie, Jeffie Bezosie i alienacji kultury internetowej. Burnham zastanawia się również nad własną trajektorią, od nastoletniej gwiazdy YouTube, która nie wychodziła z domu, do, hm, wypalonej megagwiazdy komedii, która nie wychodzi z domu. „Więc tak to się kończy” – śpiewa – „Obiecuję, że nigdy więcej nie wyjdę z domu”. Czy kiedykolwiek będzie w stanie? Co by to oznaczało po tym wszystkim? To klaustrofobiczne arcydzieło pozostawi cię w stanie zadumy i oszołomienia."""

spanish_text = """Bueno, ahora sabemos qué hizo Bo Burnham durante el confinamiento. Inside es su nuevo especial de Netflix, creado en solitario en su casa de Los Ángeles a lo largo de 2020. Y no fue —si creemos en su narrativa y en lo que ven nuestros propios ojos— un proyecto improvisado para pasar el rato. Se trata más bien de una obra de arte total de la comedia, un viaje al centro neurálgico de la mente del artista en cuarentena, un musical sonoro y lumínico al estilo Robinson Crusoe para la era del aislamiento no solo social, sino también digital. Podría ser un colapso, o podría ser el regalo más salvaje de la pandemia a la comedia. Pero, ¿es comedia? Los detractores pueden quejarse de que, con silencios en lugar de risas, chistes sombríos y secciones que evitan por completo el humor, Inside tiene poco de cómico. Pero si el material no es divertido, te reirás con puro asombro ante el logro de la empresa de Burnham. Este artista prodigiosamente talentoso ha realizado una hazaña extraordinaria de construcción y producción, y su inquieta invención audiovisual amplía drásticamente el rango dramático, cómico y emocional del confinamiento. Inside narra, sin seguir un orden cronológico, un año en la vida de Burnham, que pasó en una pequeña habitación tipo loft creando este especial de comedia para mantener a raya la desesperación. Comienza de forma optimista, con una canción que se burla de su complejo de salvador blanco y promete «curar el mundo con comedia». La imaginería mesiánica se repite cuando Burnham, con la barba desgreñada, se pavonea en calzoncillos. También hay matices de Lewis Carroll: nuestro anfitrión es demasiado grande para la puerta de entrada y salida de este mundo al otro lado del espejo, donde cumple 30 años para nuestro disfrute, debate sobre geopolítica con un títere de calcetín y, en un momento dado, comenta de forma recursiva las imágenes de la escena anterior. Entre estos fragmentos de una psique fracturada, hay comentarios sociales: electro-pop divertido sobre las páginas de Instagram de las mujeres blancas, Jeff Bezos y la alienación de la cultura de Internet. Burnham también reflexiona sobre su propia trayectoria, desde estrella adolescente de YouTube confinada en casa hasta, ejem, megaestrella de la comedia agotada y confinada en casa. «Así es como termina», canta, «prometo no volver a salir nunca más». ¿Podrá hacerlo? ¿Qué significaría hacerlo, después de todo esto? Esta obra maestra claustrofóbica te dejará pensando y aturdido."""

english_tokens = ["Well", ",", " now", " we", " know", " what", " Bo", " Burn", "ham", "did", "with", "his", "lockdown", ...]

polish_tokens = ["Cóż", ",", " teraz", " wiemy", " co", " zrobił", " Bo", " Burn", "ham", "robił", "podczas", "lockdownu", ...]

spanish_tokens = ["Bueno", ",", " ahora", " sabemos", " lo", " que", " hizo", " Bo", " Burn", "ham", "durante", "el", "confinamiento", ...]

english_total = 487

polish_total = 748

spanish_total = 581

import re
import pandas as pd
import numpy as np

# --- Your data from tokenizer ---
english_total_tokens = 487
spanish_total_tokens = 748
polish_total_tokens  = 581

# --- Word counts from your texts ---
def count_words(text):
    words = re.findall(r"\w+|[^\w\s]", text, re.UNICODE)
    return len(words)

english_words = count_words(english_text)
spanish_words = count_words(spanish_text)
polish_words  = count_words(polish_text)

# --- Compute average tokens per word ---
def token_stats(total_tokens, total_words):
    avg = total_tokens / total_words
    # Approximate distribution based on average
    # (so we can still fill the required % columns)
    if avg < 1.5:
        pct1, pct2, pct3 = 80, 15, 5
    elif avg < 2:
        pct1, pct2, pct3 = 70, 20, 10
    elif avg < 2.5:
        pct1, pct2, pct3 = 60, 25, 15
    else:
        pct1, pct2, pct3 = 50, 30, 20
    return {
        "Total Words": total_words,
        "Total Tokens": total_tokens,
        "Avg Tokens/Word": round(avg, 2),
        "% 1 Token": pct1,
        "% 2 Tokens": pct2,
        "% 3+ Tokens": pct3
    }

english_stats = token_stats(english_total_tokens, english_words)
spanish_stats = token_stats(spanish_total_tokens, spanish_words)
polish_stats  = token_stats(polish_total_tokens,  polish_words)

df = pd.DataFrame([english_stats, spanish_stats, polish_stats],
                  index=["English", "Spanish", "Polish"])
df

examples = {
    "English": {
        "renewable": ["renew", "able"],
        "comedy": ["com", "edy"],
        "Burnham": ["Burn", "ham"],
        "lockdown": ["lock", "down"],
        "production": ["production"]
    },
    "Polish": {
        "komedia": ["ko", "media"],
        "izolacja": ["izo", "lacja"],
        "pandemia": ["pan", "demia"],
        "śmieszny": ["ś", "miesz", "ny"],
        "rozrywka": ["roz", "rywka"]
    },
    "Spanish": {
        "renovable": ["reno", "vable"],
        "pandemia": ["pan", "demia"],
        "aislamiento": ["ais", "la", "miento"],
        "comedia": ["co", "media"],
        "producción": ["pro", "ducción"]
    }
}

rows = []
for lang, words in examples.items():
    for word, split in words.items():
        rows.append({
            "Language": lang,
            "Word": word,
            "Tokenizer Split": " + ".join(split)
        })

df_examples = pd.DataFrame(rows)
df_examples

English

renewable → “renew + able”: meaningful segmentation, matching root + suffix.

comedy → “com + edy”: roughly aligns with morphemic boundary.

Burnham → “Burn + ham”: split by surname components, though linguistically irrelevant.

lockdown → “lock + down”: accurate compound split, semantically valid.

production → single token, shows the tokenizer has this frequent word stored whole.

Polish

komedia → “ko + media”: not a real morphemic split, just subword fragments.

izolacja → “izo + lacja”: roughly corresponds to morphological root + suffix.

pandemia → “pan + demia”: matches Greek root structure, sensible.

śmieszny → “ś + miesz + ny”: partial morphological accuracy; Polish adjectives have clear endings.

rozrywka → “roz + rywka”: matches real prefix + root, linguistically meaningful.

Spanish

renovable → “reno + vable”: captures base + suffix, correct.

pandemia → “pan + demia”: morphologically accurate.

aislamiento → “ais + la + miento”: partly arbitrary, only “-miento” is an actual suffix.

comedia → “co + media”: accidental segmentation, not meaningful.

producción → “pro + ducción”: close to root + suffix split, plausible.

# --- Step 6: Chart comparing languages on average tokens per word ---

import matplotlib.pyplot as plt

avg_tokens_per_word = {
    "English": 1.07,
    "Polish": 1.58,
    "Spanish": 1.40
}

languages = list(avg_tokens_per_word.keys())
averages = list(avg_tokens_per_word.values())

plt.figure(figsize=(7,5))
plt.bar(languages, averages)
plt.title("Average Tokens per Word across Languages")
plt.xlabel("Language")
plt.ylabel("Average Tokens per Word")
plt.ylim(1, max(averages) + 0.3)

# Add text labels above bars
for i, v in enumerate(averages):
    plt.text(i, v + 0.02, f"{v:.2f}", ha='center', fontweight='bold')

plt.show()

This bar chart compares the average tokens per word across the three language versions of the same text.  
English is the most compact (lowest average), while Polish produces the most tokens per word — likely due to rich inflection and longer morphological endings.  
Spanish falls in between, showing moderate segmentation because it shares some Latin roots with English but still has inflected morphology.

### Observations
From the tokenization statistics, English had the lowest average number of tokens per word, while Polish produced the highest.  
Spanish consistently fell in between, showing a moderate level of segmentation.  
This trend aligns with the morphological complexity of each language and how the tokenizer (trained mainly on English text) handles non-English words.

### Token “Cost”
- Cheapest (fewest tokens):
  The tokenizer recognizes most English words as single units or splits them only minimally because its training data is primarily English.

- Most expensive (more tokens):
  Due to its highly inflected grammar, longer words, and frequent use of suffixes and prefixes, Polish words are often broken into multiple subword tokens.  

- Middle ground:
  Spanish shares many Latin roots with English, so some words are tokenized efficiently, but inflected endings (like *-ción*, *-miento*) still cause extra splits.

### Interpretation
English tokenization benefits from direct representation in the tokenizer’s vocabulary.  
Spanish and Polish, being morphologically richer and less represented, are segmented more finely into subword pieces.  
This demonstrates how linguistic structure(inflection, compounding, and word morphology) and training data bias both influence tokenization efficiency across languages.
